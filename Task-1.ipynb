{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b732a1e9-d308-40f8-bdec-d53e7a331a67",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a91444dc-83f4-4a1e-92fd-cb1a02ba3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ed45d-cf21-45ca-9c22-75a8e18185c5",
   "metadata": {},
   "source": [
    "## Loading model architecture from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cf67ddd7-8073-49d8-a097-c3499d95a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/ASHUTOSH/Desktop/EMOTION_DETECTOR/model_a.json', 'r') as json_file:\n",
    "    model_json = json_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ac5433cf-b803-48a2-849f-d942b101ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_from_json(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2e2cc-a0c8-4350-a677-68550970d3a0",
   "metadata": {},
   "source": [
    "## Loading model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2041969f-b4bf-4cc5-a1ec-646da80c3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('C:/Users/ASHUTOSH/Desktop/EMOTION_DETECTOR/model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3993c180-ff87-4cf6-a402-71f2b3c80b63",
   "metadata": {},
   "source": [
    "## Function to preprocess input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8568f6ae-bfce-44d3-ac7c-2d353f3117bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (48, 48,))\n",
    "    img = img.astype('float32')/ 255.0\n",
    "#    img =np.expand_dims(img, axis=[0, -1])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f51c8e13-3d38-473d-a94d-49876865ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert grayscale image to RGB\n",
    "def convert_to_rgb(image):\n",
    "    img_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    return img_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6cc6e8-6903-4c25-96fb-23a9f8a78f16",
   "metadata": {},
   "source": [
    "## Function to generate Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "841721df-a696-47b5-a7da-3661e61a1242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gradcam(model, img_array, layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        loss = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis = (0, 1, 2))\n",
    "\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78f9c0e-13e7-4959-bdb9-48f07c1066ce",
   "metadata": {},
   "source": [
    "## Loading an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d9ab948b-0f51-4d07-9d0c-ece4e395c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path = 'C:/Users/ASHUTOSH/Desktop/emotion images/shocked.jpg'\n",
    "#img_array = preprocess_image(image_path)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2eb7a324-37e0-4256-a6bc-89442ff8cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_image_path(root_dir):\n",
    "    class_folders = [os.path.join(root_dir, d) for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "    random_class_folder = random.choice(class_folders)\n",
    "    random_image = random.choice(os.listdir(random_class_folder))\n",
    "    return os.path.join(random_class_folder, random_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2727033a-ced5-4d3c-8896-f780db2d6700",
   "metadata": {},
   "source": [
    "# LIME Explanation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2781b97b-9259-480a-ba25-b630f83eae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_with_lime(model, image_path):\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "     # Preprocess image for LIME (should match model input size)\n",
    "    img = preprocess_image(image_path)\n",
    "    img_rgb = convert_to_rgb(img)\n",
    "#    img = cv2.cvtColor(np.squeeze(img, axis=-1), cv2.COLOR_GRAY2RGB)  # Remove single color channel dimension for LIME\n",
    "\n",
    "     # Convert grayscale to RGB by duplicating channels\n",
    "    #img_rgb = np.repeat(img, 3, axis=-1)  # Now the shape will be (48, 48, 3)\n",
    "    \n",
    "    # Define a prediction function for LIME\n",
    "    def predict_fn(images):\n",
    "#        image = np.array([cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) for image in images])\n",
    "#        images = np.expand_dims(images, axis=-1)  # Add channel dimension back\n",
    "        images_gray = np.array([cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) for image in images])\n",
    "        images_gray = np.expand_dims(images_gray, axis=-1)\n",
    "        predictions = model.predict(images)\n",
    "        return predictions\n",
    "\n",
    "    explanation = explainer.explain_instance(\n",
    "        img_rgb,\n",
    "        predict_fn,\n",
    "        top_labels=1,\n",
    "        hide_color=0,\n",
    "        num_samples=1000  # Number of perturbations to generate for each explanation\n",
    "    )\n",
    "\n",
    "    # Get explanation for the top predicted class\n",
    "    temp, mask = explanation.get_image_and_mask(\n",
    "        explanation.top_labels[0],\n",
    "        positive_only=True,\n",
    "        num_features=5,\n",
    "        hide_rest=False\n",
    "    )\n",
    "\n",
    "    plt.imshow(mark_boundaries(temp, mask))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"LIME Explanation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b7274ef0-5c6f-4b45-8230-8d6900e7dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your dataset directory\n",
    "root_dir = 'C:/Users/ASHUTOSH/Desktop/EMOTION_DETECTOR/test/'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "12bef17c-7573-4742-8b53-a594c9540eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random image path\n",
    "random_image_path = get_random_image_path(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "078814eb-fee1-4235-929a-ab8b68861530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the random image\n",
    "img_array = preprocess_image(random_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a32b38-a93e-46ef-a60e-715a1a44c6c4",
   "metadata": {},
   "source": [
    "## Generating Grad-CAM heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fe03a7ac-f0cf-4b88-86b1-9f79e43703bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'conv2d_2'\n",
    "heatmap = generate_gradcam(model, np.expand_dims(img_array, axis=0), layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e275d9-3ae0-404e-bfa7-d4229f633ac2",
   "metadata": {},
   "source": [
    "## Visualizing heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bbc6dad8-824c-43e6-aff1-382e0834649d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(heatmap, cmap='autumn')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668566c-e809-4694-912a-63b8647d993c",
   "metadata": {},
   "source": [
    "## Overlay heatmap on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "81f9e770-5aed-4254-8048-b391572a89cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread(random_image_path)\n",
    "heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap_resized = np.uint8(255 * heatmap_resized)\n",
    "heatmap_colored = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
    "\n",
    "overlay_img = cv2.addWeighted(img, 0.6, heatmap_colored, 0.4,0)\n",
    "plt.imshow(cv2.cvtColor(overlay_img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "60815d58-8c7d-4677-8af9-c9bfb48c7c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3cae4c8e2504a3c83c437d8f469f0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 48, 48, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"model\" (type Functional).\n    \n    Input 0 of layer \"conv2d_2\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 48, 48, 3)\n    \n    Call arguments received by layer \"model\" (type Functional):\n      • inputs=tf.Tensor(shape=(None, 48, 48, 3), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[220], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply LIME to explain the model prediction\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mexplain_with_lime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_image_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[213], line 21\u001b[0m, in \u001b[0;36mexplain_with_lime\u001b[1;34m(model, image_path)\u001b[0m\n\u001b[0;32m     18\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(images)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[1;32m---> 21\u001b[0m explanation \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_rgb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhide_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of perturbations to generate for each explanation\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Get explanation for the top predicted class\u001b[39;00m\n\u001b[0;32m     30\u001b[0m temp, mask \u001b[38;5;241m=\u001b[39m explanation\u001b[38;5;241m.\u001b[39mget_image_and_mask(\n\u001b[0;32m     31\u001b[0m     explanation\u001b[38;5;241m.\u001b[39mtop_labels[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     32\u001b[0m     positive_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m     num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     34\u001b[0m     hide_rest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     35\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\lime\\lime_image.py:198\u001b[0m, in \u001b[0;36mLimeImageExplainer.explain_instance\u001b[1;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[0;32m    194\u001b[0m     fudged_image[:] \u001b[38;5;241m=\u001b[39m hide_color\n\u001b[0;32m    196\u001b[0m top \u001b[38;5;241m=\u001b[39m labels\n\u001b[1;32m--> 198\u001b[0m data, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfudged_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mclassifier_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m distances \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mpairwise_distances(\n\u001b[0;32m    203\u001b[0m     data,\n\u001b[0;32m    204\u001b[0m     data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    205\u001b[0m     metric\u001b[38;5;241m=\u001b[39mdistance_metric\n\u001b[0;32m    206\u001b[0m )\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m    208\u001b[0m ret_exp \u001b[38;5;241m=\u001b[39m ImageExplanation(image, segments)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\lime\\lime_image.py:261\u001b[0m, in \u001b[0;36mLimeImageExplainer.data_labels\u001b[1;34m(self, image, fudged_image, segments, classifier_fn, num_samples, batch_size)\u001b[0m\n\u001b[0;32m    259\u001b[0m imgs\u001b[38;5;241m.\u001b[39mappend(temp)\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(imgs) \u001b[38;5;241m==\u001b[39m batch_size:\n\u001b[1;32m--> 261\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m     labels\u001b[38;5;241m.\u001b[39mextend(preds)\n\u001b[0;32m    263\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[213], line 18\u001b[0m, in \u001b[0;36mexplain_with_lime.<locals>.predict_fn\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m     16\u001b[0m images_gray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2GRAY) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images])\n\u001b[0;32m     17\u001b[0m images_gray \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(images_gray, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filed7ejxl_p.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\engine\\training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\ASHUTOSH\\anaconda3\\envs\\Emotion_detection_course\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"model\" (type Functional).\n    \n    Input 0 of layer \"conv2d_2\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 48, 48, 3)\n    \n    Call arguments received by layer \"model\" (type Functional):\n      • inputs=tf.Tensor(shape=(None, 48, 48, 3), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# Apply LIME to explain the model prediction\n",
    "explain_with_lime(model, random_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8789ae-50f9-40d4-9639-3137c0a69316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc16e5ea-ab77-45a2-8a49-e69e9df9b444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a36cd65-393f-47ad-879f-d73a83b8bb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc801b3f-07c7-4b1e-8630-2b2aaa8815cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
